{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Working with Astra DB's SAI Analyzers and Vector Search**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/msmygit/dse-tidbits/blob/master/documents/astra_vector_search_with_sai_analyzer/Vector_Search_with_AstraDB_SAI_Analyzers.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This hands-on tutorial will show you how you can add Astra DB's SAI analyzer features to power your own Generative AI applications with just a few lines of code.\n",
    "\n",
    "We will build together a sample end-to-end use case that will be able to understand and respond to human language queries about the relational data stored in your PostgreSQL database. In fact, we will further push the creative limits of the application by teaching it to generate new content based on our existing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "[Create a serverless database with Astra Vector Search and set up its schema](https://docs.datastax.com/en/astra-serverless/docs/vector-search/chatbot-quickstart.html#_prerequisites). For the reminder of this notebook, we will be using the keyspace as `baselines` and the table name as `clients` so, if you want to simply copy paste, create it the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "After completing the steps in this notebook:\n",
    "- You will have a good understanding of how to use the [SAI analyzers](https://docs.datastax.com/en/astra-serverless/docs/vector-search/using-analyzers.html) along with your vector embeddings in Astra DB. Learn more about [vector search in Astra DB](https://docs.datastax.com/en/astra-serverless/docs/vector-search/overview.html).\n",
    "- You will get a hands-on experience with using the SAI analyzers and will also have other resources to expand on.\n",
    "- _Storage-Attached Index (SAI)_ is the one that is already powering Vector Search experience within Astra DB today and these same capabilities will be contributed to Apache Cassandra¬Æ via [CEP-7](https://cwiki.apache.org/confluence/x/7DZ4CQ) & [CEP-30](https://cwiki.apache.org/confluence/x/OQ40Dw) enhancement proposals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are [many advantages to leveraging SAI](https://docs.datastax.com/en/cql/astra/docs/developing/indexing/sai/sai-concepts.html), but in particular, SAI shares common index data across multiple indexes on the same table. This unique feature gives users the ability to create many more indexes without running into scalability issues.\n",
    "\n",
    "The following charts give an indication of the space saving advantage of using SAI vs alternatives using a financial time series data model,\n",
    "\n",
    "![Alt text](./sai_disk_efficiency.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using this interactive notebook\n",
    "\n",
    "Click the **run** icon on the top left corner ‚ñ∂Ô∏è  of each cell within this notebook.\n",
    "\n",
    "> üí° Alternatively, you can run the currently selected cell with `Ctrl + Enter` (or `‚åò + Enter` on a Mac).\n",
    "\n",
    "> ‚ö†Ô∏è **To avoid any errors**, wait for each cell to finish in their order before clicking the next ‚Äúrun‚Äù icon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the table schema\n",
    "\n",
    "- Naviate to [`CQL Console`](https://docs.datastax.com/en/astra-serverless/docs/connect/cql/connect-cqlsh.html) within the Astra portal.\n",
    "- Type in `USE baselines;` and hit enter key.\n",
    "- Create the table using the below command,\n",
    "\n",
    "   ```\n",
    "   CREATE TABLE IF NOT EXISTS baselines.clients (\n",
    "       uniqueid uuid primary key,\n",
    "       firstname text,\n",
    "       lastname text,\n",
    "       birthday date,\n",
    "       nextappt timestamp,\n",
    "       newpatient boolean,\n",
    "       photo text,\n",
    "       traits vector<float, 3>\n",
    "   );\n",
    "   CREATE CUSTOM INDEX baselines_clients_birthday_idx ON baselines.clients (birthday) USING 'StorageAttachedIndex';\n",
    "   CREATE CUSTOM INDEX baselines_clients_lastname_idx ON baselines.clients (lastname) USING 'StorageAttachedIndex';\n",
    "   CREATE CUSTOM INDEX baselines_clients_traits_vector_idx ON baselines.clients (traits) USING 'StorageAttachedIndex' WITH OPTIONS = {'similarity_function': 'dot_product'};\n",
    "   ```\n",
    "- Verify the table's schema by running `DESC TABLE clients;` command in the console.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the test data\n",
    "\n",
    "Here, we will use a sample data that is prepared. The normalized (i.e. ranging from `-1` to `1`) vector embedding could be generated by leveraging services such as OpenAI, etc. Be sure to match the vector dimension in the table's column (i.e. `traits` here in our case) to the model being used. For simplicity sake, we will use the vector embedding which has a dimension of `3`.\n",
    "\n",
    "- Copy & Run the following insert statements within the Astra's CQL Console:\n",
    "    <details>\n",
    "       <summary>Expand/Collapse to view the insert statements</summary>\n",
    "       \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (D85745B1-4BEC-43D7-8B77-DD164CB9D1B8, 'Alice', 'Apple', '1984-01-24', '2020-10-20 12:00:00', true, 'imageurl1', [0.853663685, -0.370721894, -0.838156652]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (2A4F139F-0BBF-4A6F-B982-5400F11D2F2B, 'Zeke', 'Apple', '1961-12-30', '2020-10-20 12:30:00', false, 'imageurl2', [-0.2386359, 0.061663079, 0.159176746]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (DF649261-89CB-446B-9998-FFA2D17506F9, 'Lorenzo', 'Banana', '1963-09-03', '2020-10-20 13:00:00', false, 'imageurl3', [0.29688748, 0.162187505, -0.899572388]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (808E6BBF-A0F4-4E4C-9C97-E36751D51A8B, 'Miley', 'Banana', '1969-02-06', '2020-10-20 13:30:00', false, 'imageurl4', [ 0.71793891, 0.304702581, -0.319685541]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (3D458A4D-2F54-4271-BEDC-1FC316B3CC96, 'Cheryl', 'Banana', '1970-07-11', '2020-10-20 14:00:00', false, 'imageurl5', [-0.828286076, 0.951830234, 0.052958224]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (287AB6B4-1AA6-45DF-B6F8-2BE253B9AACE, 'Red', 'Currant', '1974-02-18', '2020-10-20 15:00:00', false, 'imageurl6', [-0.503873582, 0.818124782, 0.481385136]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (AB49D151-CC04-40DC-AEEA-0A4E5F59D69A, 'Matthew', 'Durian', '1976-11-11', '2020-10-19 12:30:00', false, 'imageurl7', [-0.361109664, -0.379330015, -0.725305926]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (783CE790-16B4-4645-B27C-4FDF3994A755, 'Vanessa', 'Elderberry', '1977-12-03', '2020-10-20 15:30:00', false, 'imageurl8', [0.784867341, 0.025673095, 0.828155797]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (D23997E4-CCCB-46BB-B92F-0D4582A68809, 'Elaine', 'Elderberry', '1979-11-16', '2020-10-20 10:00:00', true, 'imageurl9', [-0.241611772, -0.344717538, -0.764725406]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (36C386C1-3C3B-49FC-81B1-391D5537453D, 'Phoebe', 'Fig', '1986-01-27', '2020-10-21 11:00:00', false, 'imageurl10', [0.823133083, 0.532633194, -0.829494313]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (00FEE7EE-8F93-4C2E-A8BE-3ADD81235822, 'Patricia', 'Grape', '1986-06-24', '2020-10-21 12:00:00', false, 'imageurl11', [-0.788176132, 0.649411352, 0.930390198]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (B9DB7E99-AD1C-49B1-97C6-87154663AEF4, 'Herb', 'Huckleberry', '1990-07-09', '2020-10-21 13:00:00', false, 'imageurl12', [0.498928801, -0.835162113, -0.916987826]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (F4DB7673-CA4E-4382-BDCD-2C1704363590, 'John-Henry', 'Huckleberry', '1979-11-16', '2020-10-21 14:00:00', false, 'imageurl13', [-0.609193496, -0.077998017,     -0.       796146016]);\n",
    "         \n",
    "         INSERT INTO clients (uniqueid, firstname, lastname, birthday, nextappt, newpatient, photo, traits) \n",
    "         VALUES (F4DB7673-CA4E-4382-BDCD-2C1704363595, 'Sven', '√Ösk√•dare', '1967-11-07', '2020-10-21 14:00:00', false, 'imageurl15', [-0.97499609, -0.981892464, -0.671463954]);\n",
    "    \n",
    "    </details>\n",
    "\n",
    "- Verify by running the following command:\n",
    "    ```\n",
    "    token@cqlsh:baselines> SELECT * FROM clients ;\n",
    "    \n",
    "     uniqueid                             | birthday   | firstname  | lastname    | newpatient | nextappt                        | photo      | traits\n",
    "    --------------------------------------+------------+------------+-------------+------------+---------------------------------+------------+-----------------------------------\n",
    "     36c386c1-3c3b-49fc-81b1-391d5537453d | 1986-01-27 |     Phoebe |         Fig |      False | 2020-10-21 11:00:00.000000+0000 | imageurl10 |   [0.823133, 0.532633, -0.829494]\n",
    "     df649261-89cb-446b-9998-ffa2d17506f9 | 1963-09-03 |    Lorenzo |      Banana |      False | 2020-10-20 13:00:00.000000+0000 |  imageurl3 |   [0.296887, 0.162188, -0.899572]\n",
    "     287ab6b4-1aa6-45df-b6f8-2be253b9aace | 1974-02-18 |        Red |     Currant |      False | 2020-10-20 15:00:00.000000+0000 |  imageurl6 |   [-0.503874, 0.818125, 0.481385]\n",
    "     808e6bbf-a0f4-4e4c-9c97-e36751d51a8b | 1969-02-06 |      Miley |      Banana |      False | 2020-10-20 13:30:00.000000+0000 |  imageurl4 |   [0.717939, 0.304703, -0.319686]\n",
    "     3d458a4d-2f54-4271-bedc-1fc316b3cc96 | 1970-07-11 |     Cheryl |      Banana |      False | 2020-10-20 14:00:00.000000+0000 |  imageurl5 |    [-0.828286, 0.95183, 0.052958]\n",
    "     f4db7673-ca4e-4382-bdcd-2c1704363590 | 1979-11-16 | John-Henry | Huckleberry |      False | 2020-10-21 14:00:00.000000+0000 | imageurl13 | [-0.609194, -0.077998, -0.796146]\n",
    "     00fee7ee-8f93-4c2e-a8be-3add81235822 | 1986-06-24 |   Patricia |       Grape |      False | 2020-10-21 12:00:00.000000+0000 | imageurl11 |    [-0.788176, 0.649411, 0.93039]\n",
    "     b9db7e99-ad1c-49b1-97c6-87154663aef4 | 1990-07-09 |       Herb | Huckleberry |      False | 2020-10-21 13:00:00.000000+0000 | imageurl12 |  [0.498929, -0.835162, -0.916988]\n",
    "     ab49d151-cc04-40dc-aeea-0a4e5f59d69a | 1976-11-11 |    Matthew |      Durian |      False | 2020-10-19 12:30:00.000000+0000 |  imageurl7 |   [-0.36111, -0.37933, -0.725306]\n",
    "     d23997e4-cccb-46bb-b92f-0d4582a68809 | 1979-11-16 |     Elaine |  Elderberry |       True | 2020-10-20 10:00:00.000000+0000 |  imageurl9 | [-0.241612, -0.344718, -0.764725]\n",
    "     f4db7673-ca4e-4382-bdcd-2c1704363595 | 1967-11-07 |       Sven |    √Ösk√•dare |      False | 2020-10-21 14:00:00.000000+0000 | imageurl15 | [-0.974996, -0.981892, -0.671464]\n",
    "     2a4f139f-0bbf-4a6f-b982-5400f11d2f2b | 1961-12-30 |       Zeke |       Apple |      False | 2020-10-20 12:30:00.000000+0000 |  imageurl2 |   [-0.238636, 0.061663, 0.159177]\n",
    "     d85745b1-4bec-43d7-8b77-dd164cb9d1b8 | 1984-01-24 |      Alice |       Apple |       True | 2020-10-20 12:00:00.000000+0000 |  imageurl1 |  [0.853664, -0.370722, -0.838157]\n",
    "     783ce790-16b4-4645-b27c-4fdf3994a755 | 1977-12-03 |    Vanessa |  Elderberry |      False | 2020-10-20 15:30:00.000000+0000 |  imageurl8 |    [0.784867, 0.025673, 0.828156]\n",
    "    \n",
    "    (14 rows)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leveraging SAI in the read queries\n",
    "\n",
    "- All the below examples will be using index based reads without involving the traditional primary key approach.\n",
    "- Now that we've all the data and indices set, let's start reading back the data. Let's try to use basic index first,\n",
    "\n",
    "  ```\n",
    "  token@cqlsh:baselines> SELECT firstname FROM baselines.clients WHERE lastname = 'Apple';\n",
    "  \n",
    "   firstname\n",
    "  -----------\n",
    "        Zeke\n",
    "       Alice\n",
    "  \n",
    "  (2 rows)\n",
    "  ```\n",
    "- Let's read the desired data back using the vector index, i.e. let's perform a vector search:\n",
    "\n",
    "  ```\n",
    "  token@cqlsh:baselines> SELECT firstname FROM baselines.clients ORDER BY traits ANN OF [0.5,0.5,0.5] LIMIT 5;\n",
    "  \n",
    "   firstname | traits\n",
    "  -----------+---------------------------------\n",
    "     Vanessa |  [0.784867, 0.025673, 0.828156]\n",
    "         Red | [-0.503874, 0.818125, 0.481385]\n",
    "    Patricia |  [-0.788176, 0.649411, 0.93039]\n",
    "       Miley | [0.717939, 0.304703, -0.319686]\n",
    "      Phoebe | [0.823133, 0.532633, -0.829494]\n",
    "  \n",
    "  (5 rows)\n",
    "  ```\n",
    "\n",
    "- Now, let's combine the regular index with vector search:\n",
    "\n",
    "  ```\n",
    "  token@cqlsh:baselines> SELECT firstname, traits FROM baselines.clients WHERE lastname = 'Apple' ORDER BY traits ANN OF [0.5,0.5,0.5] LIMIT 5;\n",
    "  token@cqlsh:baselines> SELECT * FROM baselines.clients WHERE lastname = 'Apple';\n",
    "  \n",
    "   uniqueid                             | birthday   | firstname  | lastname    | newpatient | nextappt                        | photo      | traits\n",
    "  --------------------------------------+------------+------------+-------------+------------+---------------------------------+------------+-----------------------------------\n",
    "   2a4f139f-0bbf-4a6f-b982-5400f11d2f2b | 1961-12-30 |       Zeke |       Apple |      False | 2020-10-20 12:30:00.000000+0000 |  imageurl2 |   [-0.238636, 0.061663, 0.159177]\n",
    "   d85745b1-4bec-43d7-8b77-dd164cb9d1b8 | 1984-01-24 |      Alice |       Apple |       True | 2020-10-20 12:00:00.000000+0000 |  imageurl1 |  [0.853664, -0.370722, -0.838157]\n",
    "  \n",
    "  (2 rows)\n",
    "  ```\n",
    "\n",
    "- We could do powerful composing of regular indicies with vector search as follows too:\n",
    "\n",
    "  ```\n",
    "  token@cqlsh:baselines> token@cqlsh:baselines> SELECT * FROM baselines.clients WHERE birthday > '1990-01-01' OR lastname = 'Fig' ORDER BY traits ANN OF [0.5,0.5,0.5] LIMIT 5;\n",
    "  \n",
    "   uniqueid                             | birthday   | firstname | lastname    | newpatient | nextappt                        | photo      | traits\n",
    "  --------------------------------------+------------+-----------+-------------+------------+---------------------------------+------------+----------------------------------\n",
    "   36c386c1-3c3b-49fc-81b1-391d5537453d | 1986-01-27 |    Phoebe |         Fig |      False | 2020-10-21 11:00:00.000000+0000 | imageurl10 |  [0.823133, 0.532633, -0.829494]\n",
    "  \n",
    "  (1 rows)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leveraging Analyzers with vector search on the reads\n",
    "\n",
    "Using analyzers with vector search allows you to create a hybrid search that includes your keyword and a vector embedding. Instead of returning only a list of results, a large language model (LLM) can return similar results based on the analyzer, which could be a brand or size or in our example a particular trait.\n",
    "\n",
    "For example, if you ask an LLM ‚ÄúTell me about available shoes‚Äù and this query is done with vector search against your Astra DB table, you would get a list of several shoes with a variety of features.\n",
    "\n",
    "- We will drop the existing index on `lastname` column by running `DROP INDEX baselines_clients_lastname_idx;`\n",
    "\n",
    "- We can create an SAI index using the new index_analyzer option.  Usually standard is a good starting point:\n",
    "\n",
    "  ```\n",
    "  CREATE CUSTOM INDEX baselines_clients_lastname_idx_analyzer ON baselines.clients (lastname) USING 'StorageAttachedIndex' WITH OPTIONS = { 'index_analyzer': 'standard'};\n",
    "  ```\n",
    "\n",
    "- And you can query like this to get both rows.  Note how the analyzer takes care of splitting the text up into case-independent terms. Notice our input with all lowercase `banana`:\n",
    "\n",
    "  ```\n",
    "  token@cqlsh:baselines> SELECT firstname, lastname FROM baselines.clients WHERE lastname : 'banana';\n",
    "  \n",
    "   firstname | lastname\n",
    "  -----------+----------\n",
    "     Lorenzo |   Banana\n",
    "       Miley |   Banana\n",
    "      Cheryl |   Banana\n",
    "  \n",
    "  (3 rows)\n",
    "  ```\n",
    "\n",
    "- Now comes the powerful part of combining the analyzers with the vector search. You get the approximate nearest neighbor of the relevant _traits_ plus you could combine to further filter result to your custom liking, let's say the clients with lastname of `banana`:\n",
    "\n",
    "  ```\n",
    "  token@cqlsh:baselines> SELECT firstname, lastname FROM baselines.clients WHERE lastname : 'banana' ORDER BY traits ANN OF [0.29, 0.95, 0.05] LIMIT 5;\n",
    "  \n",
    "   firstname | lastname | traits\n",
    "  -----------+----------+---------------------------------\n",
    "      Cheryl |   Banana |  [-0.828286, 0.95183, 0.052958]\n",
    "       Miley |   Banana | [0.717939, 0.304703, -0.319686]\n",
    "     Lorenzo |   Banana | [0.296887, 0.162188, -0.899572]\n",
    "  \n",
    "  (3 rows)\n",
    "  ```\n",
    "- Points to be noted in the earlier query are:\n",
    "  - It automatically matches the rows with lastname `Bananas` (case-insensitive).\n",
    "  - And, it filters the `5` vector search matches further down with the analyzer output.\n",
    "\n",
    "- Now, what if we want to search using a stemmed word like `Bananas`? This below query would yield no results because standard analyzer does not include [stemming](https://en.wikipedia.org/wiki/Stemming):\n",
    "\n",
    "  ```\n",
    "  token@cqlsh:baselines> select * from clients where lastname : 'Bananas';\n",
    "  \n",
    "   uniqueid | birthday | firstname | lastname | newpatient | nextappt | photo | traits\n",
    "  ----------+----------+-----------+----------+------------+----------+-------+--------\n",
    "  \n",
    "  (0 rows)\n",
    "  ```\n",
    "\n",
    "- This is where custom configuration of the analyzer comes into play. There is one primary option to customize for now. There could be more coming in future.\n",
    "  - `index_analyzer`: configures how to analyze the column‚Äôs values before indexing them. Note that this analyzer is applied to the query‚Äôs term search as well.\n",
    "\n",
    "- We will drop the existing index on `lastname` column by running `DROP INDEX baselines_clients_lastname_idx_analyzer;` and re-create it as follows to enable [stemming](https://en.wikipedia.org/wiki/Stemming):\n",
    "\n",
    "  ```\n",
    "  CREATE CUSTOM INDEX baselines_clients_lastname_idx_analyzer ON baselines.clients (lastname) USING 'StorageAttachedIndex' WITH OPTIONS = {'index_analyzer': '{ \"tokenizer\" :   {\"name\" : \"standard\"}, \"filters\" : [{\"name\" : \"porterstem\"}] }'};\n",
    "\n",
    "  token@cqlsh:baselines> SELECT firstname, lastname, traits FROM baselines.clients WHERE lastname : 'Bananas' ORDER BY traits ANN OF [0.29, 0.95, 0.05] LIMIT 5;\n",
    "  \n",
    "   firstname | lastname | traits\n",
    "  -----------+----------+---------------------------------\n",
    "      Cheryl |   Banana |  [-0.828286, 0.95183, 0.052958]\n",
    "       Miley |   Banana | [0.717939, 0.304703, -0.319686]\n",
    "     Lorenzo |   Banana | [0.296887, 0.162188, -0.899572]\n",
    "  \n",
    "  (3 rows)\n",
    "  ```\n",
    "\n",
    "- Refer to [this documentation](https://docs.datastax.com/en/astra-serverless/docs/vector-search/using-analyzers.html) for other power user configuration options.\n",
    "\n",
    "### (Optional) More complex example using an `edgeNGram` tokenizer\n",
    "Tokenizes the input from an edge into n-grams of given size(s). This `Tokenizer` create n-grams from the beginning edge of a input token.\n",
    "\n",
    "Index creation in this case will be as follows:\n",
    "```\n",
    "CREATE CUSTOM INDEX baselines_clients_firstname_idex_analyzer ON baselines.clients (firstname) USING 'StorageAttachedIndex' WITH OPTIONS = {\n",
    "  'index_analyzer': '{\n",
    "    \"tokenizer\" : {\n",
    "      \"name\" : \"edgeNGram\",\n",
    "      \"args\" : {\n",
    "            \"minGramSize\":\"1\",\n",
    "            \"maxGramSize\":\"3\"\n",
    "            }\n",
    "    },\n",
    "    \"filters\" : [\n",
    "      {\n",
    "        \"name\" : \"lowercase\",\n",
    "        \"args\": {}\n",
    "      }\n",
    "    ],\n",
    "    \"charFilters\" : []\n",
    "  }'\n",
    "};\n",
    "```\n",
    "\n",
    "The following queries will now be possible unlocking even more use cases:\n",
    "- `SELECT * FROM baselines.clients WHERE firstname : 'ph';`\n",
    "- `SELECT * FROM baselines.clients WHERE firstname : 'phOEbE';`\n",
    "- `SELECT * FROM baselines.clients WHERE firstname : 'phOEbE' ORDER BY traits ANN OF [0.29, 0.95, 0.05] LIMIT 1;`\n",
    "\n",
    "Results will be:\n",
    "```\n",
    "token@cqlsh:baselines> SELECT * FROM baselines.clients WHERE firstname : 'phOEbE' ORDER BY traits ANN OF [0.29, 0.95, 0.05] LIMIT 1;\n",
    "\n",
    " uniqueid                             | birthday   | firstname | lastname | newpatient | nextappt                        | photo      | traits\n",
    "--------------------------------------+------------+-----------+----------+------------+---------------------------------+------------+---------------------------------\n",
    " 36c386c1-3c3b-49fc-81b1-391d5537453d | 1986-01-27 |    Phoebe |      Fig |      False | 2020-10-21 11:00:00.000000+0000 | imageurl10 | [0.823133, 0.532633, -0.829494]\n",
    "\n",
    "(1 rows)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (Optional) Cleaning up\n",
    "When you no longer need your database along with the data, you could [terminate your database](https://docs.datastax.com/en/astra-serverless/docs/manage/db/manage-terminate-db.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative AI is a powerful paradigm shift in application development that lets you create novel applications to serve users in new ways - [from answering patients' complex medical questions](https://cloud.google.com/blog/topics/healthcare-life-sciences/sharing-google-med-palm-2-medical-large-language-model) to [helping enterprises analyze cyberattacks](https://cloud.google.com/blog/products/identity-security/rsa-google-cloud-security-ai-workbench-generative-ai). In this demo, we showed you just a couple examples of powerful Astra features that you can leverage further to create powerful experiences by combining LLMs, Agents, [**LangStream**](https://docs.langstream.ai) and Astra platform.\n",
    "\n",
    "We can't wait to see what you build with it! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
